{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b980b91-2f45-496d-91f8-b78c49f5c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9312832a-2223-4865-9f9d-1e8de7042507",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_generation/simple_linear_regression.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1040798-66b6-4b4d-9ed7-1200b9fedefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c538ace-6308-42c7-bcde-7aba595cfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be6089c-c23a-424b-987b-d4332b540851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v0.py\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Set model to TRAIN mode\n",
    "    model.train()\n",
    "    # Step 1- Computes model's predicted output - forward parss\n",
    "    yhat = model(x_train_tensor)\n",
    "    # Step 2 = Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" paramters\n",
    "    loss.backward()\n",
    "    # Step 4 - Updats parameters using gradients and the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408eebe4-6874-45fd-8f91-b92e01b632ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a86e1e9-1579-4f50-bde6-96c2586a9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step_fn(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step_fn(x, y):\n",
    "        # Set model to TRAIN mode\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return perform_train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1cb9692-6b53-434c-9ead-0067b7737160",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ae2ae2-cebf-4b65-a83a-e9e228f76332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v1.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0595ef4-7364-4f03-853b-1eabf6832da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85ee1d8-dfa7-40d2-b179-3f04c536c377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_train_step_fn.<locals>.perform_train_step_fn(x, y)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b07ebc24-306d-4a7d-8e12-631a603bb13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v1.py\n",
    "\n",
    "n_epochs = 1000\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = train_step_fn(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20687616-9808-4cf3-a4be-eac9b5ab9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238def16-86fa-404c-adee-5f0e9d23962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f45570-0673-425c-9e97-be8a348f62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6109cdf3-65b0-4629-a379-f5ce3af79bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "tain_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4743ede3-ee8e-41c4-bed4-bc4b79e85d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912c9815-2c7c-44f9-b1ac-1bf835ed27c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2809],\n",
       "         [0.3253],\n",
       "         [0.1560],\n",
       "         [0.5924],\n",
       "         [0.0651],\n",
       "         [0.8872],\n",
       "         [0.4938],\n",
       "         [0.0055],\n",
       "         [0.1409],\n",
       "         [0.0885],\n",
       "         [0.1849],\n",
       "         [0.7290],\n",
       "         [0.8662],\n",
       "         [0.3117],\n",
       "         [0.6842],\n",
       "         [0.1987]]),\n",
       " tensor([[1.5846],\n",
       "         [1.8057],\n",
       "         [1.2901],\n",
       "         [2.1687],\n",
       "         [1.1559],\n",
       "         [2.8708],\n",
       "         [1.9060],\n",
       "         [1.0632],\n",
       "         [1.1211],\n",
       "         [1.0708],\n",
       "         [1.5888],\n",
       "         [2.4927],\n",
       "         [2.6805],\n",
       "         [1.7637],\n",
       "         [2.3492],\n",
       "         [1.2654]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb255a84-ff54-4fa9-9620-8357a0be766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v1.py\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "# Builds Dataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Builds DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d324efc-690a-4356-8050-32c4520b9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "092c5d3a-aa07-4ea1-a530-a5c39be2894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5180b798-c992-4312-848d-95564eba4f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v2.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # Performs one train step and returns the \n",
    "        # corresponding loss for this mini-batch\n",
    "        mini_batch_loss = train_step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    # Computes average loss over all mini-batches\n",
    "    # That's the epoch loss\n",
    "    loss = np.mean(mini_batch_loss)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc961fe8-065c-420e-ad1a-494695748b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e92af5b5-e5f7-44af-a46d-2b6821e72120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9696]], device='cuda:0')), ('0.bias', tensor([1.0243], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "054aad0b-f66f-4ec2-b547-fd540e8c562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(device, data_loader, step_fn):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f31dd521-8d00-4bc2-9b16-31588535438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py\n",
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df8ae83b-e200-4daf-971e-9ad4de7ec338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v3.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # innner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fa444cf-d426-4294-afe7-882e0d43a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96f22f4e-ee22-439c-8b8a-a1aa5912174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9684]], device='cuda:0')), ('0.bias', tensor([1.0219], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fa75f2b-5972-42f1-b90f-c98d24ebcc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "# Builds tensors from numpy arrays BEFORE  split\n",
    "x_tensor = torch.as_tensor(x).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performas the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "train_data, val_data = random_split(dataset, [n_train,n_val])\n",
    "\n",
    "# Buidls a loader of each set\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2fb5350-784e-452b-bd4d-a26d4e25737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0e6940d-2fd3-4c99-9077-38f4d1d23fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_step_fn(model, loss_fn):\n",
    "    # Builds function that performs a step in\n",
    "    # the validation loop\n",
    "    def perform_val_step_fn(x, y):\n",
    "        model.eval()\n",
    "        # step 1 - Computes our model's predicted output\n",
    "        # forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - computes the losss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # There is not need step3 and 4, \n",
    "        # since we don't update parameters during evaluation\n",
    "        return loss.item()\n",
    "    return perform_val_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1979e7fa-791d-4be5-b43e-3a53b808bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v2.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "# Define an SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define an MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Create the train_step function for our model, loss function and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the val_step function for our model and loss function\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ea027ab-fba4-4f95-b88a-bdd56fc59664",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd0fda9-dfc5-468e-bd62-c620f37c9e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v4.py\n",
    "\n",
    "n_epochs = 200\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Validation -no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss =mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ccddad4-01a3-4674-9f63-aa074bbd3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c94e1dbd-6666-4b8a-a79b-08774c0c32bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9438]], device='cuda:0')), ('0.bias', tensor([1.0287], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf886e5-d968-497b-8d12-d8c76b747a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e949a7d-9b0d-43b5-bcbb-31794708a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20196), started 0:09:13 ago. (Use '!kill 20196' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f4609c4b54f13aa2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f4609c4b54f13aa2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3f5ae12-d71a-440a-b5d9-2dcc27087f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b11331cb-5504-47db-83d9-24a74832561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aea6f4fa-6170-4378-8d46-390a85a41362",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars(\n",
    "    main_tag='loss',\n",
    "    tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
    "    global_step=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f8bbe5c-94ec-4f6b-955d-1962f2fdb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8760b2c-60ce-4494-b1f3-5adb9a255b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "# Define an SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define an MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Create the train_step function for our model, loss function and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the val_step function for our model and loss function\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to itnerface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e43c7a7-e062-436b-98ca-ec2303e05a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45f069e4-4594-4305-ade9-a20b242b28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "\n",
    "n_epochs = 200\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Validation -no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss =mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)\n",
    "    # Records both losses for each epoch under tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                      tag_scalar_dict={\n",
    "                          'training': loss,\n",
    "                          'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d497e14d-757e-41e1-931c-fa67dbc04bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "836b39a1-b542-4428-a72a-e75b8b41df02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9432]], device='cuda:0')), ('0.bias', tensor([1.0263], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e125e200-eaba-49e7-bd7a-d421e241c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-78f829c42b59e98a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-78f829c42b59e98a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/simple_linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0be4b294-62d6-4aca-beda-5e8dc09804d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkoutpoint = {'epoch': n_epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': losses,\n",
    "                'val_loss': val_losses}\n",
    "torch.save(checkoutpoint, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "077425d5-069e-48ec-a943-3038eb1d2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration//v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a0ec8dd-c71c-40c3-9f3e-d97d44472127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')), ('0.bias', tensor([0.8300], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8e4e26e-9644-4004-b80a-f9f1d955488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkoutpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkoutpoint['optimizer_state_dict'])\n",
    "\n",
    "saved_epoch = checkoutpoint['epoch']\n",
    "saved_losses = checkoutpoint['loss']\n",
    "saved_val_losses = checkoutpoint['val_loss']\n",
    "\n",
    "model.train()  # always use TRAIN fro resuming traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "189e06fa-394e-4e2a-886f-2960340b0102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9432]], device='cuda:0')), ('0.bias', tensor([1.0263], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85950348-3328-4453-b5ef-13326ec676c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08e60012-be0f-4cb8-9992-b7a824e7e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9432]], device='cuda:0')), ('0.bias', tensor([1.0263], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2d2b16d-b1e3-4f0a-975b-f4e74ec16862",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "204373e3-73b6-42d2-ad68-325f2fbe274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9432]], device='cuda:0')), ('0.bias', tensor([1.0263], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkoutpoint['model_state_dict'])\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "675590d9-645a-4326-ae61-cc307317b46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4150],\n",
       "        [1.6870],\n",
       "        [2.1340]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs = torch.tensor([[.20], [.34], [.57]])\n",
    "\n",
    "model.eval() # always use EVAL for fullly trained models\n",
    "model(new_inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c21b9f7-d2ab-4c5f-a2e3-562629e76b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "# Builds tensors from numpy arrays BEFORE  split\n",
    "x_tensor = torch.as_tensor(x).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performas the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "train_data, val_data = random_split(dataset, [n_train,n_val])\n",
    "\n",
    "# Buidls a loader of each set\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dccca150-a9c1-49ae-ab8a-0d1dabeddd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "# Define an SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define an MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Create the train_step function for our model, loss function and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the val_step function for our model and loss function\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to itnerface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "\n",
    "writer.add_graph(model, dummy_x.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "831dab3b-a79c-4a85-8fcf-5894bc4815c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v5.py\n",
    "\n",
    "n_epochs = 200\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Validation -no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss =mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)\n",
    "    # Records both losses for each epoch under tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                      tag_scalar_dict={\n",
    "                          'training': loss,\n",
    "                          'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79c2721f-1a43-4944-85d5-33a430fca9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9432]], device='cuda:0')), ('0.bias', tensor([1.0263], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432811e8-f67b-46af-af61-61b2882fb65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
